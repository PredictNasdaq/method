{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/seonahryu/Desktop/urp/duplicated_sentiment_nasdaq.csv\", index_col='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-1~1 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         text  \\\n",
      "date                                                            \n",
      "2009-05-05  Donald Trump will be appearing on The View tom...   \n",
      "2009-05-08  Donald Trump reads Top Ten Financial Tips on L...   \n",
      "2009-05-09  New Blog Post: Celebrity Apprentice Finale and...   \n",
      "2009-05-12  \"\"\"My persona will never be that of a wallflow...   \n",
      "2009-05-12  \"Miss USA Tara Conner will not be fired - \"\"I'...   \n",
      "2009-05-13  Listen to an interview with Donald Trump discu...   \n",
      "2009-05-14  \"\"\"Strive for wholeness and keep your sense of...   \n",
      "2009-05-15  \"Enter the \"\"Think Like A Champion\"\" signed bo...   \n",
      "2009-05-19  \"\"\"...these days...we could all use a little o...   \n",
      "2009-05-20  \"\"\"Always know you could be on the precipice o...   \n",
      "\n",
      "            vader_sentiment  roberta_sentiment  past_day_close      Open  \\\n",
      "date                                                                       \n",
      "2009-05-05                1                  0       -0.989263 -0.990806   \n",
      "2009-05-08                1                  1       -0.994376 -0.993383   \n",
      "2009-05-09                0                  0       -0.991917 -0.993383   \n",
      "2009-05-12                0                 -1       -0.992755 -0.992368   \n",
      "2009-05-12                1                  0       -0.992755 -0.992368   \n",
      "2009-05-13                1                  0       -0.994410 -0.997363   \n",
      "2009-05-14                0                  1       -1.000000 -1.000000   \n",
      "2009-05-15                1                  0       -0.997297 -0.998372   \n",
      "2009-05-19                0                  0       -0.992634 -0.994088   \n",
      "2009-05-20                0                  1       -0.992399 -0.992287   \n",
      "\n",
      "                High       Low        Close    Volume  Adj Close  \n",
      "date                                                              \n",
      "2009-05-05 -0.993328 -0.992238  1754.119995 -0.673712  -0.990249  \n",
      "2009-05-08 -0.994627 -0.994894  1739.000000 -0.554696  -0.991888  \n",
      "2009-05-09 -0.994627 -0.994894  1739.000000 -0.554696  -0.991888  \n",
      "2009-05-12 -0.995048 -0.996545  1715.920044 -0.684961  -0.994391  \n",
      "2009-05-12 -0.995048 -0.996545  1715.920044 -0.684961  -0.994391  \n",
      "2009-05-13 -1.000000 -1.000000  1664.189941 -0.706116  -1.000000  \n",
      "2009-05-14 -0.999626 -0.999591  1689.209961 -0.740642  -0.997287  \n",
      "2009-05-15 -0.999384 -0.998651  1680.140015 -0.759370  -0.998271  \n",
      "2009-05-19 -0.994342 -0.993923  1734.540039 -0.756005  -0.992372  \n",
      "2009-05-20 -0.992456 -0.993661  1727.839966 -0.722975  -0.993098  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 데이터 정규화\n",
    "features_to_scale = ['past_day_close', 'Open', 'High', 'Low', 'Volume', 'Adj Close'] # nasdaq 지수만 정규화\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentiment 범위 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Sentiment - 최대값: 1, 최소값: -1\n",
      "Roberta Sentiment - 최대값: 1, 최소값: -1\n"
     ]
    }
   ],
   "source": [
    "# 최대값과 최소값 계산\n",
    "vader_max = df['vader_sentiment'].max()\n",
    "vader_min = df['vader_sentiment'].min()\n",
    "roberta_max = df['roberta_sentiment'].max()\n",
    "roberta_min = df['roberta_sentiment'].min()\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"VADER Sentiment - 최대값: {vader_max}, 최소값: {vader_min}\")\n",
    "print(f\"Roberta Sentiment - 최대값: {roberta_max}, 최소값: {roberta_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 튜닝을 위해 keras tuner 설치\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 데이터셋 생성 함수 정의\n",
    "def create_dataset(X, y, time_step=30):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_step):\n",
    "        Xs.append(X[i:(i + time_step)])\n",
    "        ys.append(y[i + time_step])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 및 성능 평가 함수 정의\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "    return mse, rmse, r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['vader_sentiment']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 1), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 1  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\lstm\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 하이퍼파라미터 튜닝을 위한 모델 정의\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=10, max_value=100, step=10), \n",
    "                   return_sequences=True,\n",
    "                   input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=10, max_value=100, step=10)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='tanh')) # -1~1 정규화해서 출력층 tanh func\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Keras Tuner 설정\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=200,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='lstm')\n",
    "\n",
    "# 조기 종료 콜백 정의\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86 Complete [00h 00m 40s]\n",
      "val_loss: 0.2339242845773697\n",
      "\n",
      "Best val_loss So Far: 0.23280903697013855\n",
      "Total elapsed time: 00h 53m 47s\n",
      "\n",
      "Search: Running Trial #87\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "100               |60                |units\n",
      "0.2               |0.5               |dropout_rate\n",
      "30                |60                |units_2\n",
      "0.1               |0.5               |dropout_rate_2\n",
      "3                 |3                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "4                 |4                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/3\n",
      "\u001b[1m260/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2447"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['roberta_sentiment']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 1), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 1  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : VADER + RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['vader_sentiment', 'roberta_sentiment']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 2), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 2  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : past_day_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['past_day_close']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 1), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 1  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : past_day_close + VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['past_day_close', 'vader_sentiment']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 2), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 2  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : past_day_close + RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['past_day_close', 'roberta_sentiment']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 2), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 2  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : past_day_close + VADER + RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['past_day_close', 'vader_sentiment', 'roberta_sentiment']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 3), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 3  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['Open', 'High', 'Low', 'Volume']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 4), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 4  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume + past_day_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['Open', 'High', 'Low', 'Volume', 'past_day_close']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 5), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 5  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume + past_day_close + VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['Open', 'High', 'Low', 'Volume', 'past_day_close', 'vader_sentiment']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 6), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 6  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume + past_day_close + RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['Open', 'High', 'Low', 'Volume', 'past_day_close', 'roberta_sentiment']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 6), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 6  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume + past_day_close + VADER + RoBERTa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df에서 input과 Adj Close 준비\n",
    "features_1d = df[['Open', 'High', 'Low', 'Volume', 'past_day_close', 'vader_sentiment', 'roberta_sentiment']].values.flatten()\n",
    "target_1d = df['Adj Close'].values.flatten()  # Adj Close 열 사용\n",
    "\n",
    "# 데이터셋을 7:3 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_1d.reshape(-1, 7), target_1d, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "X_train, y_train = create_dataset(X_train, y_train)\n",
    "X_test, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# feature 수 정의\n",
    "num_features = 7  # X의 feature 수\n",
    "\n",
    "# X의 형태 조정: (samples, time_steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 탐색\n",
    "# 배치 사이즈를 하이퍼파라미터로 추가\n",
    "batch_sizes = [128, 256, 512, 1024, 2048]  # 다양한 배치 사이즈 설정\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=20,  # 짧은 에포크 수로 조정\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 callbacks=[early_stopping],\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for hp, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hp}: {value}\")\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 최적의 배치 사이즈로 모델 학습\n",
    "final_batch_size = best_hyperparameters.get('batch_size', 512)  # 하이퍼파라미터에서 가져오거나 기본값 설정\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=final_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 손실 기록 저장\n",
    "history_dict[final_batch_size] = history.history\n",
    "\n",
    "# 모델 평가 및 예측 수행\n",
    "mse, rmse, r_squared = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test MSE: {mse:.3f}, Test RMSE: {rmse:.3f}, R-squared: {r_squared:.2f}\")\n",
    "\n",
    "# 예측값 저장\n",
    "predictions_dict[final_batch_size] = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
