{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/seonahryu/Desktop/urp/duplicated_sentiment_nasdaq.csv\", index_col='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-1~1 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 데이터 정규화\n",
    "features_to_scale = ['past_day_close', 'Open', 'High', 'Low', 'Volume', 'Adj Close'] # nasdaq 지수만 정규화\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentiment 범위 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대값과 최소값 계산\n",
    "vader_max = df['vader_sentiment'].max()\n",
    "vader_min = df['vader_sentiment'].min()\n",
    "roberta_max = df['roberta_sentiment'].max()\n",
    "roberta_min = df['roberta_sentiment'].min()\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"VADER Sentiment - 최대값: {vader_max}, 최소값: {vader_min}\")\n",
    "print(f\"Roberta Sentiment - 최대값: {roberta_max}, 최소값: {roberta_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER Sentiment 정규화\n",
    "min_vader = vader_min\n",
    "max_vader = vader_max\n",
    "\n",
    "# 정규화: -1에서 1 사이로 변환\n",
    "df['vader_sentiment'] = 2 * ((df['vader_sentiment'] - min_vader) / (max_vader - min_vader)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 데이터셋 생성 함수 정의\n",
    "def create_dataset(X, y, time_step=30):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_step):\n",
    "        Xs.append(X[i:(i + time_step)])\n",
    "        ys.append(y[i + time_step])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 및 성능 평가 함수 정의\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "    return mse, rmse, r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# LSTM 모델 정의\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))  # Input 레이어 추가\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='tanh'))  # -1~1 정규화해서 출력층 tanh 함수\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# EarlyStopping 콜백 정의\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vader = ['vader_sentiment']\n",
    "\n",
    "X, y = create_dataset(df[vader].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "roberta = ['roberta_sentiment']\n",
    "\n",
    "X, y = create_dataset(df[roberta].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : VADER + RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sentiment = ['vader_sentiment', 'roberta_sentiment']\n",
    "\n",
    "X, y = create_dataset(df[sentiment].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : past_day_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "past_day_close = ['past_day_close']\n",
    "\n",
    "X, y = create_dataset(df[past_day_close].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : past_day_close + VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "past_vader = ['past_day_close', 'vader_sentiment']\n",
    "\n",
    "X, y = create_dataset(df[past_vader].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : past_day_close + RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "past_roberta = ['past_day_close', 'roberta_sentiment']\n",
    "\n",
    "X, y = create_dataset(df[past_roberta].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : past_day_close + VADER + RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "past_sentiment = ['past_day_close', 'vader_sentiment', 'roberta_sentiment']\n",
    "\n",
    "X, y = create_dataset(df[past_sentiment].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nasdaq = ['Open', 'High', 'Low', 'Volume']\n",
    "\n",
    "X, y = create_dataset(df[nasdaq].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume + past_day_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "past_nasdaq = ['Open', 'High', 'Low', 'Volume', 'past_day_close']\n",
    "\n",
    "X, y = create_dataset(df[past_nasdaq].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume + past_day_close + VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "past_nasdaq_vader = ['Open', 'High', 'Low', 'Volume', 'past_day_close', 'vader_sentiment']\n",
    "\n",
    "X, y = create_dataset(df[past_nasdaq_vader].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume + past_day_close + RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "past_nasdaq_roberta = ['Open', 'High', 'Low', 'Volume', 'past_day_close', 'roberta_sentiment']\n",
    "\n",
    "X, y = create_dataset(df[past_nasdaq_roberta].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input : Open + High + Low + Volume + past_day_close + VADER + RoBERTa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "past_nasdaq_sentiment = ['Open', 'High', 'Low', 'Volume', 'past_day_close', 'vader_sentiment', 'roberta_sentiment']\n",
    "\n",
    "X, y = create_dataset(df[past_nasdaq_sentiment].values, df['Adj Close'].values)\n",
    "\n",
    "# 데이터셋을 train+validation, test 나누기 (8:2)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# train, validation (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 배치 크기로 모델 학습\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "predictions_dict = {}  # 예측값 저장\n",
    "history_dict = {}  # 손실 기록 저장\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    # 손실 기록 저장\n",
    "    history_dict[batch_size] = history.history\n",
    "\n",
    "    # 예측 수행 및 평가\n",
    "    mse, rmse, r_squared = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # 예측값 저장\n",
    "    predictions_dict[batch_size] = model.predict(X_test).flatten()\n",
    "\n",
    "    # 성능 출력\n",
    "    print(f'Batch Size: {batch_size}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R-squared: {r_squared:.3f}')\n",
    "    # r_squared = 회귀 모델의 성능을 평가하는 데 사용되는 지표, 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지 나타냄.\n",
    "    # 일반적으로 0.7 이상이면 좋은 모델. 0과 1 사이의 값을 가짐!\n",
    "    # 음수값이면 모델이 평균값 예측하는 것보다 더 나쁜 성능... 모델이 데이터에 적합하지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(y_test.flatten(), label='Actual Values', color='blue', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(predictions_dict[batch_size], label=f'Predicted Values (Batch Size: {batch_size})', color='red')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted Values (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history_dict[batch_size]['loss'], label='Train Loss')\n",
    "    plt.plot(history_dict[batch_size]['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss Curves (Batch Size: {batch_size})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
